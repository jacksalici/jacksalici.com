---
title: "Leveraging Gaze Estimation in Human-Robot Interaction:
development of a Framework for Eye Tracking in the Wild"
description: "My thesis is about gaze, eyes, smart glasses, robot and 3d space reconstruction."
layout: "../layouts/Page.astro"
summary: "The following is a glimpse of my master degree thesis in Computer Engineering. During its development I researched about the eye and gaze tracking importance in human robot interaction, I then built a framework to estimate it in the wild (that means not in a lab)."
translateLink: True
---

## Abstract

Humanity has always developed tools and skills to simplify tasks and improve the quality of life. Since the invention of robotic arms, these machines have reduced the physical demands of labor-intensive jobs and increased safety. With the advent of artificial intelligence, robots are becoming more empathetic and interactive, making robust human-robot interaction (HRI) essential. A key aspect of interactive robots is their ability to detect a user's intention to engage and interpret their focus of attention â€” tasks where estimating human gaze plays a crucial role.

The goal of this thesis is to develop a framework for gaze estimation and eye tracking. Firstly, it addresses the practical challenge of estimating eye movements "in the wild." Secondly, it provides a baseline for future research in this field. The framework makes use of Meta's Project Aria glasses, a device designed to accelerate research in augmented and extended reality (AR/XR), and integrates several technologies, from neural networks to Structure From Motion (SFM) processing. The gaze direction can effectually be localized within a 3D environment, allowing tracking across multiple third-person perspectives.

A new dataset has also been recorded to demonstrate the framework's capabilities and offer a potential benchmark and validation tool for new gaze estimation models. The dataset consists of recordings of participants performing common actions while wearing Project Aria glasses, captured from another pair of glasses and a Pepper robot. This dataset could address existing challenges in the field and advance further research in HRI.